{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE4211 Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "       Team 1: Quadratic                   Done by Choi Jae Hyung, Lee Min Young, Nicholas Lui Ming Yang, Tran Duy Anh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from scipy import stats\n",
    "from functools import reduce\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"project_data.csv\")\n",
    "# df.shape - (1584823, 3)\n",
    "# df column values:\n",
    "# localminute - Timestamp \n",
    "# dataid - MeterID \n",
    "# meter_value - meter reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many houses are included in the measurement study?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since dataid is unique for each meter, we can count the number of unique dataid numbers\n",
    "df.dataid.value_counts().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This gives us 157 for the number of houses included in the study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are there any malfunctioning meters? If so, identify them and the time periods where they were malfunctioning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are various ways to define a malfunctioning meter. Let us explore some of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us first check, if there are *meters that report a lower value at a later timestamp*. Since meter_value is cumulative consumption, meter_value should not be lower at a later timestamp for the same meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(['dataid'], sort=['localminute'])\n",
    "def has_decreasing_values(df):\n",
    "    current_value = 0\n",
    "    for index, val in df.iteritems():\n",
    "        if val < current_value:\n",
    "            return True\n",
    "        current_value = val\n",
    "        \n",
    "meters_with_decreasing = (grouped['meter_value']\n",
    "                          .agg(has_decreasing_values)\n",
    "                          .where(lambda x: x)\n",
    "                          .dropna()\n",
    "                          .keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Int64Index([  35,   77,   94,  483,  484, 1042, 1086, 1185, 1507, 1556, 1718,\n",
       "            1790, 1801, 2129, 2335, 2449, 3134, 3527, 3544, 3893, 4031, 4193,\n",
       "            4514, 4998, 5129, 5131, 5193, 5403, 5810, 5814, 5892, 6836, 7017,\n",
       "            7030, 7117, 7739, 7794, 7989, 8156, 8890, 9134, 9639, 9982],\n",
       "           dtype='int64', name='dataid')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(meters_with_decreasing))\n",
    "meters_with_decreasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wow, we have 43 meters that have a decreasing value! Let's zoom in and get the offending sections for each meter. (In other words, find the exact data points which show this descreasing value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to re-sort after filter since filter takes all rows and breaks original sorting\n",
    "dec_meters = (grouped.filter(lambda x: int(x.name) in meters_with_decreasing)\n",
    "              .groupby(['dataid'], sort=['localminute']))\n",
    "\n",
    "## Iterate over values to find offending rows for each meter\n",
    "## WARNING: RUNS VERY SLOWLY. TODO: OPTIMIZE\n",
    "offending_values = {}\n",
    "for group_id, rows in dec_meters.groups.items():\n",
    "    offending_values[group_id] = []\n",
    "    current_value = 0\n",
    "    group_rows = dec_meters.get_group(group_id)\n",
    "    group_rows_count = group_rows.shape[0]\n",
    "    for i in range(group_rows_count):\n",
    "        if group_rows.iloc[i]['meter_value'] < current_value:\n",
    "            offending_values[group_id].append([group_rows.iloc[i-1], group_rows.iloc[i]])\n",
    "        current_value = group_rows.iloc[i]['meter_value']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of 'broken data' instances for each meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meter ID | Number of broken readings\n",
      "35                   1\n",
      "77                   1\n",
      "94                   6\n",
      "483                  1\n",
      "484                  9\n",
      "1042                 1\n",
      "1086                 1\n",
      "1185                 135\n",
      "1507                 2\n",
      "1556                 12\n",
      "1718                 4\n",
      "1790                 1\n",
      "1801                 1\n",
      "2129                 3\n",
      "2335                 5\n",
      "2449                 93\n",
      "3134                 18\n",
      "3527                 1\n",
      "3544                 18\n",
      "3893                 2\n",
      "4031                 16\n",
      "4193                 1\n",
      "4514                 141\n",
      "4998                 1\n",
      "5129                 76\n",
      "5131                 1\n",
      "5193                 4\n",
      "5403                 156\n",
      "5810                 10\n",
      "5814                 1\n",
      "5892                 1\n",
      "6836                 51\n",
      "7017                 1\n",
      "7030                 90\n",
      "7117                 123\n",
      "7739                 1\n",
      "7794                 1\n",
      "7989                 2\n",
      "8156                 151\n",
      "8890                 44\n",
      "9134                 115\n",
      "9639                 2\n",
      "9982                 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Meter ID |\", \"Number of broken readings\")\n",
    "for k, v in offending_values.items():\n",
    "    print(str(k).ljust(20), len(v))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Just knowing the number of broken readings may not be useful. \n",
    "##### Let's say that we want to know which meters should be fixed, since faulty meters result in us inaccurately measuring consumption, and possibly losing money.\n",
    "##### There should be some measure of tolerance in deciding if a meter is broken. In this case, let's check the average decreasing amount, and the ratio of \"broken\" readings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meter ID | Number of broken readings | Average decrease across broken readings | Percentage of broken readings for meter\n",
      "35                   1                    2.0                                      0.008423180592991915\n",
      "77                   1                    2.0                                      0.009360666479453337\n",
      "94                   6                    9.0                                      0.016513003990642632\n",
      "483                  1                    14.0                                     0.0036195164326046038\n",
      "484                  9                    2.4444444444444446                       0.020438751873552256\n",
      "1042                 1                    2.0                                      0.02610966057441253\n",
      "1086                 1                    2.0                                      0.003330114222917846\n",
      "1185                 135                  16267.674074074097                       0.7314694408322496\n",
      "1507                 2                    2.0                                      0.006134404809373371\n",
      "1556                 12                   13574.0                                  0.3252032520325203\n",
      "1718                 4                    5.0                                      0.016346546791990192\n",
      "1790                 1                    2.0                                      0.007494004796163069\n",
      "1801                 1                    2.0                                      0.006292474200855777\n",
      "2129                 3                    2.0                                      0.021759628635671283\n",
      "2335                 5                    22942.0                                  0.05611672278338946\n",
      "2449                 93                   15472.860215053784                       1.7067351807671134\n",
      "3134                 18                   12877.222222222224                       0.4480955937266617\n",
      "3527                 1                    2.0                                      0.009214042200313279\n",
      "3544                 18                   8488.222222222223                        0.8104457451598379\n",
      "3893                 2                    2.0                                      0.007450454477723141\n",
      "4031                 16                   2.875                                    0.1276527844263603\n",
      "4193                 1                    2.0                                      0.09813542688910697\n",
      "4514                 141                  23971.8156028369                         0.7392261717521234\n",
      "4998                 1                    14.0                                     0.007156147130385\n",
      "5129                 76                   11116.815789473698                       1.6941596076683014\n",
      "5131                 1                    2.0                                      0.00658457891617831\n",
      "5193                 4                    5.0                                      0.02055076037813399\n",
      "5403                 156                  10897.37179487177                        0.6103525177041355\n",
      "5810                 10                   4.6000000000000005                       0.023677605720509542\n",
      "5814                 1                    2.0                                      0.0023571563266075804\n",
      "5892                 1                    2.0                                      0.007072635971426551\n",
      "6836                 51                   11397.17647058824                        1.1283185840707965\n",
      "7017                 1                    4.0                                      0.0039558526840460465\n",
      "7030                 90                   17217.15555555556                        0.5023723137036004\n",
      "7117                 123                  16809.414634146335                       0.6002049480310351\n",
      "7739                 1                    2.0                                      0.022558087074216106\n",
      "7794                 1                    6.0                                      0.011724703951225232\n",
      "7989                 2                    26.0                                     0.005034866450167409\n",
      "8156                 151                  16260.622516556286                       0.596932321315623\n",
      "8890                 44                   2.6363636363636354                       0.26547604682032094\n",
      "9134                 115                  32439.008695652185                       0.8176905574516496\n",
      "9639                 2                    29376.0                                  0.014496955639315743\n",
      "9982                 2                    14036.0                                  0.12987012987012986\n"
     ]
    }
   ],
   "source": [
    "print(\"Meter ID |\", \"Number of broken readings |\", \"Average decrease across broken readings |\", \"Percentage of broken readings for meter\")\n",
    "for k, v in offending_values.items():\n",
    "    print(str(k).ljust(20), \n",
    "          str(len(v)).ljust(20), \n",
    "          str(reduce(lambda x, y: x + abs(y[1]['meter_value'] - y[0]['meter_value']) / len(v), [0] + v )).ljust(40), \n",
    "          (len(v) / dec_meters.get_group(k).shape[0]) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With the data laid out like this, it is pretty clear that most meters are not really broken if we allow a 2% error rate\n",
    "#### However, in terms of error volume, some are pretty suspect. Let's use an average volume error of 100 Cubic foot (that's a lot!) as our threshold, and filter our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meter ID | Number of broken readings | Average decrease across broken readings | Percentage of broken readings for meter\n",
      "483                  1                    14.0                                     0.0036195164326046038\n",
      "1185                 135                  16267.674074074097                       0.7314694408322496\n",
      "1556                 12                   13574.0                                  0.3252032520325203\n",
      "2335                 5                    22942.0                                  0.05611672278338946\n",
      "2449                 93                   15472.860215053784                       1.7067351807671134\n",
      "3134                 18                   12877.222222222224                       0.4480955937266617\n",
      "3544                 18                   8488.222222222223                        0.8104457451598379\n",
      "4514                 141                  23971.8156028369                         0.7392261717521234\n",
      "4998                 1                    14.0                                     0.007156147130385\n",
      "5129                 76                   11116.815789473698                       1.6941596076683014\n",
      "5403                 156                  10897.37179487177                        0.6103525177041355\n",
      "6836                 51                   11397.17647058824                        1.1283185840707965\n",
      "7030                 90                   17217.15555555556                        0.5023723137036004\n",
      "7117                 123                  16809.414634146335                       0.6002049480310351\n",
      "7989                 2                    26.0                                     0.005034866450167409\n",
      "8156                 151                  16260.622516556286                       0.596932321315623\n",
      "9134                 115                  32439.008695652185                       0.8176905574516496\n",
      "9639                 2                    29376.0                                  0.014496955639315743\n",
      "9982                 2                    14036.0                                  0.12987012987012986\n"
     ]
    }
   ],
   "source": [
    "print(\"Meter ID |\", \"Number of broken readings |\", \"Average decrease across broken readings |\", \"Percentage of broken readings for meter\")\n",
    "for k, v in offending_values.items():\n",
    "    measure = str(reduce(lambda x, y: x + abs(y[1]['meter_value'] - y[0]['meter_value']) / len(v), [0] + v )).ljust(40)\n",
    "    if float(measure) > 10:\n",
    "        print(str(k).ljust(20), \n",
    "              str(len(v)).ljust(20), \n",
    "              measure, \n",
    "              (len(v) / dec_meters.get_group(k).shape[0]) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time apart |         meter value initial | meter value after | difference\n",
      "0 days 00:00:13           203154               203152               -2\n",
      "0 days 00:06:59           203580               203578               -2\n",
      "0 days 01:52:10.446150    223266               206892               -16374\n",
      "0 days 00:15:09.023424    223266               206892               -16374\n",
      "0 days 00:01:10.125932    223268               206910               -16358\n",
      "0 days 02:14:09.533295    223282               206986               -16296\n",
      "0 days 00:21:08.597335    223304               207046               -16258\n",
      "0 days 01:39:08.641617    223306               207048               -16258\n",
      "0 days 01:41:09.602248    223318               207066               -16252\n",
      "0 days 00:46:07.782113    223320               207080               -16240\n",
      "0 days 01:13:08.190968    223332               207094               -16238\n",
      "0 days 00:14:06.456241    223340               207104               -16236\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Use this function to validate/check each bad meter given our heuristic\"\"\"\n",
    "def print_bad_meter_readings(meterID):\n",
    "    meter_readings = offending_values[meterID]\n",
    "    print(\"time apart |\".ljust(20), \"meter value initial |\", \"meter value after |\", \"difference\")\n",
    "    for readings_pair in meter_readings:\n",
    "\n",
    "        print(str(pd.to_datetime(readings_pair[1]['localminute']) - pd.to_datetime(readings_pair[0]['localminute'])).ljust(25), \n",
    "              str(readings_pair[0]['meter_value']).ljust(20), \n",
    "              str(readings_pair[1]['meter_value']).ljust(20), \n",
    "              readings_pair[1]['meter_value'] - readings_pair[0]['meter_value'])\n",
    "print_bad_meter_readings(1556)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another requirement of the meters is that they push their readings to be saved if the meter values differ by at least 2 cubic foot\n",
    "#### Let us verify that every pair of readings for a meter differ by at least 2 cubic foot. To not double count, we will only check for readings where the differing value is 0 >= x > 2 so that we don't get the same error readings where the readings decrease\n",
    "#### Since the value is smaller, we will not focus on the difference in values, but on the percentage of total readings for the meter only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of meters with stagnant values:  155\n"
     ]
    }
   ],
   "source": [
    "grouped2 = df.groupby(['dataid'], sort=['localminute'])\n",
    "def has_stagnant_values(df):\n",
    "    current_value = 0\n",
    "    for index, val in df.iteritems():\n",
    "        if index == 0:\n",
    "            current_value = val\n",
    "            continue\n",
    "        \n",
    "        if val < current_value + 2 and val >= current_value:\n",
    "            return True\n",
    "        current_value = val\n",
    "        \n",
    "meters_with_stagnant = (grouped['meter_value']\n",
    "                          .agg(has_stagnant_values)\n",
    "                          .where(lambda x: x)\n",
    "                          .dropna()\n",
    "                          .keys())\n",
    "\n",
    "print(\"Number of meters with stagnant values: \", len(meters_with_stagnant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following segment should have calculated the percentage of stagnant values for each meter, but it takes too long (tried for 5 minutes and gave up). At least we know number of meters that reported stagnant values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Need to re-sort after filter since filter takes all rows and breaks original sorting\n",
    "# stagnant_meters = (grouped2.filter(lambda x: int(x.name) in meters_with_stagnant)\n",
    "#               .groupby(['dataid'], sort=['localminute']))\n",
    "\n",
    "# ## Iterate over values to count offending occurences. Not counting value\n",
    "# ## WARNING: RUNS VERY SLOWLY. TODO: OPTIMIZE\n",
    "# offending_values2 = {}\n",
    "# for group_id, rows in stagnant_meters.groups.items():\n",
    "#     offending_values2[group_id] = 0\n",
    "#     group_rows = stagnant_meters.get_group(group_id)\n",
    "#     group_rows_count = group_rows.shape[0]\n",
    "#     # Set current_value so we do not trigger first reading\n",
    "#     current_value = group_rows.iloc[0]['meter_value'] - 5\n",
    "#     for i in range(group_rows_count):\n",
    "#         if group_rows.iloc[i]['meter_value'] < current_value + 2 and group_rows.iloc[i]['meter_value'] >= current_value:\n",
    "#             offending_values2[group_id] += 1\n",
    "#         current_value = group_rows.iloc[i]['meter_value']\n",
    "\n",
    "        \n",
    "# print(\"Meter ID |\", \"Number of broken readings |\", \"Percentage of broken readings for meter\")\n",
    "# for k, v in offending_values2.items():\n",
    "#     print(str(k).ljust(20), \n",
    "#           str(v).ljust(20),  \n",
    "#           (v / stagnant_meters.get_group(k).shape[0]) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of readings to iterate, which is why it is slow:  1584818\n"
     ]
    }
   ],
   "source": [
    "stagnant_meters = (grouped2.filter(lambda x: int(x.name) in meters_with_stagnant)\n",
    "              .groupby(['dataid'], sort=['localminute']))\n",
    "\n",
    "print(\"Total number of readings to iterate, which is why it is slow: \", \n",
    "      reduce(lambda x, y: x + len(y), [0] + list(stagnant_meters.groups.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now have two different criterion for deciding what constitues a broken meter, and the readings that helped us determine that. Since the question asks for \"time periods where they were malfunctioning.\", let's demonstrate that we can consolidate broken readings into time periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use the meter with the most broken readings (based off decreasing values)\n",
    "most_broken_values_meter = grouped.get_group(5403)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using a stricter requirement now. Let's consider that, if the subsequent meter reading is less \n",
    "# than an increment of 2 (meters are only supposed to report after at least an increment of 2)\n",
    "\n",
    "# Broken_criteria is a helper function (comparator function) that takes in two (in-order) readings and outputs a \n",
    "# boolean of whether the later reading is \"broken\"\n",
    "\n",
    "broken_criteria = lambda x, y: y['meter_value'] < x['meter_value'] + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of broken readings for meter 5403, based on stricter requirements:  21371\n"
     ]
    }
   ],
   "source": [
    "broken_readings = 0\n",
    "num_readings = most_broken_values_meter.shape[0]\n",
    "for i in range(1, num_readings):\n",
    "    if broken_criteria(most_broken_values_meter.iloc[i-1], most_broken_values_meter.iloc[i]):\n",
    "        broken_readings += 1\n",
    "\n",
    "print(\"Number of broken readings for meter 5403, based on stricter requirements: \", broken_readings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now create a function that can aggregate a meter's readings into \"broken\" time periods\n",
    "# Return value of the function will be as follow:\n",
    "\"\"\"\n",
    "2D array. \n",
    "First dimension is the time periods. \n",
    "Second dimension is the consecutive broken readings that make up the broken time period\n",
    "To find the actual time data, take the ['localminute'] attribute from the first and last reading per period\n",
    "    time_periods = [\n",
    "        [reading_1, reading_2, reading_3],\n",
    "        [reading_1, reading_2]\n",
    "    ]\n",
    "\"\"\"\n",
    "def get_broken_time_periods(broken_criteria, meter_readings):\n",
    "    num_readings = meter_readings.shape[0]\n",
    "    time_periods = []\n",
    "    temp_period = []\n",
    "    for i in range(1, num_readings):\n",
    "        if broken_criteria(meter_readings.iloc[i-1], meter_readings.iloc[i]):\n",
    "            temp_period.append(meter_readings.iloc[i])\n",
    "        else:\n",
    "            if temp_period:\n",
    "                time_periods.append(temp_period)\n",
    "                temp_period = []\n",
    "    if temp_period:\n",
    "        time_periods.append(temp_period)\n",
    "    return time_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of broken time periods:  3545\n"
     ]
    }
   ],
   "source": [
    "broken_time_periods = get_broken_time_periods(broken_criteria, most_broken_values_meter)\n",
    "print(\"Number of broken time periods: \", len(broken_time_periods))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1.2 \n",
    "## Hourly Data Collection and Plotting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objective: \n",
    "Obtain hourly data from a list of given data, and plot the obtained data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters: \n",
    "#### 1. Gas meter ID \n",
    "Gas meter with ID 739 will be focused for the study\n",
    "#### 2. Starting time\n",
    "6th Oct 2015, 12 a.m.\n",
    "#### 3. Ending time\n",
    "5th Nov 2015, 11 p.m."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assumption (How we aggregate the data into hourly readings)\n",
    "- The data is always cumulative: increasing in value as time goes.\n",
    "\n",
    "The lowest value in an hour should be the closest value to an exact hour (hh:00:00) and a good estimate of that hour's data.\n",
    "\n",
    "Therefore, the first data point in an hour is used to represent the hourly data. (The assumption is that we are interested in approximating the consumption amount at the start of the hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to handle missing data?\n",
    "As the data is cumulative gas consumption by household, when there is no data, it can be assumed as there is insignificant gas consumption between that period.\n",
    "\n",
    "Hence, the missing data will be given same value as most recent hourly data obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bad data readings\n",
    "This plot of hourly readings does not account for \"bad\" data readings (consecutive reading with a lower value, which should not happen for cumulative consumption data)\n",
    "\n",
    "The likelihood of seeing an hourly data point that is bad is Average P(bad readings an hour) * (4*60), since we have max 4 readings per minute\n",
    "\n",
    "This reduces the code complexity to get a plot, and the usefulness of this approach depends on the usage of this plot\n",
    "\n",
    "If we are simply looking for a general consumption level visualisation, then this plot should suffice. However, if we are looking for plots with a decrease in value to identify faulty meters, then this plot is insufficient. For that, we cannot hold our original assumption (that readings are cumulative and strictly increasing), and should take the MIN(hour_values) to represent that hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The algorithm of hourly data collection consists of the functions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In every new hour, collect the lowest value as the hourly data.\n",
    "\n",
    "\n",
    "2. Look out for missing hour. When missing hour is found, previuos hour data is given for that hour.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hourly Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create DateHour column, that represents \"Date + Hour\" of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change to datetime format\n",
    "df[\"localminute\"] = pd.to_datetime(df[\"localminute\"])\n",
    "#get a dataframe of data by hour:\n",
    "df_byhour = pd.DataFrame(df.groupby([df[\"localminute\"].dt.date.rename(\"Date\"), \n",
    "                               df[\"localminute\"].dt.hour.rename(\"Hour\"), \n",
    "                               df[\"dataid\"]]).min().reset_index())\n",
    "\n",
    "# To preview df_byhour sorted by meter and time\n",
    "# df_byhour = df_byhour.sort_values=(by=['dataid', 'Date', 'Hour'])\n",
    "\n",
    "#add a column called \"DateHour\" in the dataframe:\n",
    "df_byhour['DateHour'] = pd.to_datetime(df_byhour['Date'].apply(str)+' '+df_byhour['Hour'].apply(str)+':00:00')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose the meter_ID, starting time and ending time of the hourly data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format: ID No.\n",
    "ID = 739\n",
    "\n",
    "#ranges from 06/10/2015 00:00:00 to 05/11/2015 23:00:00\n",
    "start_date = datetime.date(2015, 10, 5)\n",
    "end_date = datetime.date(2015, 11, 6)\n",
    "filteredDF = df_byhour[(df_byhour[\"Date\"] > start_date) & (df_byhour[\"Date\"] < end_date)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect hourly data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from 06/10/2015 -> 06/11/2015 there are 31 days -> 744 data points\n",
    "prevHr = pd.Timestamp('2015-10-06 00:00:00')\n",
    "endHr = pd.Timestamp('2015-11-05 23:00:00')\n",
    "#generate a temporary dataframe through get_group function with each id\n",
    "dfTemp = filteredDF.groupby(['dataid']).get_group(ID)\n",
    "#get the list of hours and meter values\n",
    "hourList = dfTemp['DateHour'].tolist()\n",
    "valList = dfTemp['meter_value'].tolist()\n",
    "#re-initialize the prev val as the first value of the val list\n",
    "prevVal = valList[0]\n",
    "#re-initialize the list of values as a list with 1 item\n",
    "newList = [valList[0]]\n",
    "#loop through each hour in the list\n",
    "for index, hr in enumerate(hourList):\n",
    "    #if hour is more than an hour bigger than previous\n",
    "    while (hr - prevHr).seconds >= 3600:\n",
    "        newList.append(prevVal)\n",
    "        #increment every hour\n",
    "        prevHr += pd.Timedelta(seconds=3600)\n",
    "        \n",
    "    #update the prev value everytime one index is passed\n",
    "    prevVal = valList[index]\n",
    "    \n",
    "#some data does not reach until the end date, thats where this comes in\n",
    "while prevHr < endHr:\n",
    "    newList.append(prevVal)\n",
    "    #increment every hour\n",
    "    prevHr += pd.Timedelta(seconds=3600)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the hourly reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.date_range(datetime.date(2015, 10, 6), datetime.date(2015, 11, 6), freq = 'H').tolist()\n",
    "#get rid of the last hour which is 00:00:00 06/11/2016\n",
    "x.pop()\n",
    "y = newList\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 6))\n",
    "ax.plot(x, y, 'ok', ms=1)\n",
    "plt.xlabel (\"Time\")\n",
    "plt.ylabel (\"Meter value\")\n",
    "ax.set_title('Hourly Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.3 Find for each home, 5 houses with highest correlation\n",
    "\n",
    "#### Uses Numpy.corrcoeff to get Pearson product-moment correlation coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of meter id\n",
    "idList = df['dataid'].unique()\n",
    "\n",
    "df[\"localminute\"] = pd.to_datetime(df[\"localminute\"])\n",
    "#get a dataframe of data by hour:\n",
    "df_byhour = pd.DataFrame(df.groupby([df[\"localminute\"].dt.date.rename(\"Date\"), \n",
    "                               df[\"localminute\"].dt.hour.rename(\"Hour\"), \n",
    "                               df[\"dataid\"]]).mean().reset_index())\n",
    "\n",
    "#add a column called \"DateHour\" in the dataframe:\n",
    "df_byhour['DateHour'] = pd.to_datetime(df_byhour['Date'].apply(str)+' '+df_byhour['Hour'].apply(str)+':00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are 183 days => 4392 hours => 4392 readings in each list\n",
    "#generate a dictionary\n",
    "hourlyDataDict = {}\n",
    "\n",
    "#define start hour and end hour\n",
    "staHr = pd.Timestamp('2015-10-01 05:00:00')\n",
    "endHr = pd.Timestamp('2016-04-01 04:00:00')\n",
    "\n",
    "#loop through each id \n",
    "for id1 in idList:\n",
    "    \n",
    "    #re-innitialize the prev Hour as start hour\n",
    "    prevHr = staHr\n",
    "    #generate a temporary dataframe through get_group function with each id\n",
    "    dfTemp = df_byhour.groupby(['dataid']).get_group(id1)\n",
    "    #get the list of hours and meter values\n",
    "    hourList = dfTemp['DateHour'].tolist()\n",
    "    valList = dfTemp['meter_value'].tolist()\n",
    "    #re-initialize the prev pal as the first value of the val list\n",
    "    prevVal = valList[0]\n",
    "    #re-initialize the list of values as a list with 1 item\n",
    "    newList = [valList[0]]\n",
    "    #loop through each hour in the list\n",
    "    for index, hr in enumerate(hourList):\n",
    "        #if hour is more than an hour bigger than previous\n",
    "        while (hr - prevHr).seconds >= 3600:\n",
    "            newList.append(prevVal)\n",
    "            #increment every hour\n",
    "            prevHr += pd.Timedelta(seconds=3600)\n",
    "        \n",
    "        #update the prev value everytime one index is passed\n",
    "        prevVal = valList[index]\n",
    "    \n",
    "    #some data does not reach until the end date, thats where this comes in\n",
    "    while prevHr < endHr:\n",
    "        newList.append(prevVal)\n",
    "        #increment every hour\n",
    "        prevHr += pd.Timedelta(seconds=3600)\n",
    "    \n",
    "    #after all that create a new entry in the Dictionary with the key as the id and value is the list of meter readings\n",
    "    hourlyDataDict[id1] = newList\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Dictionary of Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corDict = {}\n",
    "#loop through id List to get the first id\n",
    "for id1 in idList:\n",
    "    #create the empty value for the first key\n",
    "    corDict[id1] = {}\n",
    "    #loop through the id list to get the second id\n",
    "    for id2 in idList:\n",
    "        # generate the coefficient through numpy.corrcoef (can be changed later)\n",
    "        coef = np.corrcoef(hourlyDataDict[id1], hourlyDataDict[id2])[0, 1]\n",
    "        # assign the value to the dict with the appropriate key\n",
    "        corDict[id1][id2] = coef\n",
    "        #print(\"coefficient between \" + str(id1) + \" and \" + str(id2) + \" is: \" + str(coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's find the top 5 houses with highest correlation value for each house "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "idList.sort()\n",
    "top5dict = {}\n",
    "\n",
    "for id in idList:\n",
    "    \n",
    "    #### This is if you just want the houseID for each (first column being the ID)\n",
    "    \n",
    "#     print(sorted(corDict[id], key =corDict[id].get, reverse=True)[:6])\n",
    "    \n",
    "    #### This is if you want to get the houseID + the value of correlation coefficient\n",
    "    c = Counter(corDict[id])\n",
    "    mc = c.most_common(6)\n",
    "    del mc[0]\n",
    "    \n",
    "    top5dict.update({id : mc})\n",
    "    \n",
    "top5dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
